{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Clustering<h3>--with Naive Bayes Classification</h3></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<ul>\n",
    "<li>\n",
    "Text Clustering is one of the application of Naive Bayes classfication. We can perform text clustering on articles, document, emails for classify them into different topics such as science, life style, Automation etc.\n",
    "</li>\n",
    "<li>\n",
    "But there is one problem with ML algorithm, it can only deal with numeric values and not with String. To deal with these problem we have to transform the data into numeric values.\n",
    "</li>\n",
    "<li>\n",
    "Ok wait! We are not going to do that tedious task Python will do that for us;)\n",
    "</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Concept of Term frequency and Inverse document frequency<p>(TF-IDF)</p></h3>\n",
    "\n",
    "\n",
    "<p>\n",
    "<ul>\n",
    "<li>\n",
    "My name is Utsav\n",
    "</li>\n",
    "<li>\n",
    "That is my dog\n",
    "</li>\n",
    "</p>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<thead>\n",
    "<tr>\n",
    "    <th>My</th>\n",
    "    <th>name</th>\n",
    "    <th>is</th>\n",
    "    <th>Utsav</th>\n",
    "    <th>that</th>\n",
    "    <th>Dog</th>\n",
    "</tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>fd</th></tr>\n",
    "<tr><th>rt</th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "        <tr>\n",
    "            <td>2D Gray scale</td>\n",
    "            <td>(row,columns)</td>\n",
    "        </tr>        \n",
    "        <tr>\n",
    "            <td>2D Multichannel</td>\n",
    "            <td>(row,column, channel)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3D gray scale (for volumetric)</td>\n",
    "            <td>(plane, row, channel)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3D multi channel</td>\n",
    "            <td>(plane, row,column, channel)</td>\n",
    "        </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<ul>\n",
    "<li>\n",
    "First row represents first sentence and second row represents second sentence.\n",
    "</li>\n",
    "<li>\n",
    "This Matrix is known as Document Term matrix. It is quite understandable. Here in place of sentences we can also put big articles, document etc.  \n",
    "</li>\n",
    "<li>\n",
    "Now, see the words such as My, is, that, the and so on doesn't contain much information, hence we have to get rid of that.\n",
    "</li>\n",
    "<li>\n",
    "Hence with tf-idf approach we can measure similarities between two articles, document etc\n",
    "</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Term Frequency</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It measures the occurence of a specific word w in a document d</p>\n",
    "\n",
    "<p><b>Formula</b></p>\n",
    "<p>\n",
    "No. of times w appears in d/Total no. of words in d\n",
    "</p>\n",
    "<p>\n",
    "<ul><li>\n",
    "More the word appears in the document, more relevant it is to the document.\n",
    "</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inverse Document frequency</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><ul><li>\n",
    "It says that, more the word appears in numerous articles, more it is <b>irrelevant</b>.\n",
    "</li>\n",
    "<p><b>Formula</b></p>\n",
    "<li>\n",
    "Log(No. of documents/No. of document that contains word w)\n",
    "</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Product of Term frequency and Inverse document frequency describes the importance or relevance of string representations (words, phrases, lemmas, etc) in a document amongst a collection of documents.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We are here using dataset of 20 news Group</h3>\n",
    "<p>Below is the categories of the news</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"alt.atheism\",\"soc.religion.christian\",\"comp.graphics\",\"sci.med\"]\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train',shuffle=True,random_state=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data\n",
    "#train_data.target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is:  comp.os.ms-windows.misc\n"
     ]
    }
   ],
   "source": [
    "print(\"Target is: \",train_data.target_names[train_data.target[30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vector = CountVectorizer()\n",
    "x_train_counts = count_vector.fit_transform(train_data.data)\n",
    "print(train_data.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 125053)\t0.05027305592917851\n",
      "  (0, 124616)\t0.057123500780181066\n",
      "  (0, 124332)\t0.07608225488581496\n",
      "  (0, 124055)\t0.042033746927754606\n",
      "  (0, 123984)\t0.0348875918092499\n",
      "  (0, 123792)\t0.17482932129764958\n",
      "  (0, 123292)\t0.0687954225134742\n",
      "  (0, 123264)\t0.10481717091280113\n",
      "  (0, 119237)\t0.1496896568940949\n",
      "  (0, 118983)\t0.03510691351222197\n",
      "  (0, 118960)\t0.11009786412388954\n",
      "  (0, 116448)\t0.10043020357983931\n",
      "  (0, 115475)\t0.040206110835853175\n",
      "  (0, 114838)\t0.11757890368397594\n",
      "  (0, 114800)\t0.05098467860137924\n",
      "  (0, 114625)\t0.048115136518877014\n",
      "  (0, 114455)\t0.01938672611146808\n",
      "  (0, 112144)\t0.088238974577872\n",
      "  (0, 112031)\t0.05740101030442567\n",
      "  (0, 111322)\t0.018134434582310566\n",
      "  (0, 111183)\t0.16225948909587223\n",
      "  (0, 108871)\t0.07870205210704306\n",
      "  (0, 108821)\t0.05405517043346927\n",
      "  (0, 108809)\t0.0586741248407353\n",
      "  (0, 108494)\t0.13711982469231757\n",
      "  :\t:\n",
      "  (11313, 31439)\t0.07545930330700214\n",
      "  (11313, 30303)\t0.04341108634809611\n",
      "  (11313, 30044)\t0.018005037853324923\n",
      "  (11313, 29573)\t0.01759946103912343\n",
      "  (11313, 29463)\t0.03370475936617696\n",
      "  (11313, 29241)\t0.03280141874705281\n",
      "  (11313, 29207)\t0.05417578161079167\n",
      "  (11313, 28983)\t0.06178169448584646\n",
      "  (11313, 28601)\t0.040056111544711295\n",
      "  (11313, 28417)\t0.053884383427454996\n",
      "  (11313, 28281)\t0.057372345560862716\n",
      "  (11313, 28146)\t0.04729495481584835\n",
      "  (11313, 27721)\t0.026006134807500848\n",
      "  (11313, 27436)\t0.03865332489840551\n",
      "  (11313, 26343)\t0.04778975857821046\n",
      "  (11313, 25404)\t0.0962114618535959\n",
      "  (11313, 25210)\t0.08929407567139798\n",
      "  (11313, 23380)\t0.08370928988942723\n",
      "  (11313, 14532)\t0.06536385119437775\n",
      "  (11313, 14064)\t0.06709304730758768\n",
      "  (11313, 11545)\t0.04287283597552118\n",
      "  (11313, 6513)\t0.05621956405694469\n",
      "  (11313, 5583)\t0.08706717471616285\n",
      "  (11313, 4605)\t0.03298965561702417\n",
      "  (11313, 700)\t0.08706717471616285\n"
     ]
    }
   ],
   "source": [
    "#we transform word occurences into tfidf\n",
    "# TfidVectoriser = CountVectoriser + TfidTransformer\n",
    "tfid_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfid_transformer.fit_transform(x_train_counts)\n",
    "print(x_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(x_train_tfidf, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [\n",
    "\"This is about Hinduisam\",\n",
    "\"Hp Computers are very good\",\"yyy ttt ggg yymee\",\n",
    "\" sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content\",\n",
    "\"Computer graphics is a sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Now, we will,\n",
    "<ul>\n",
    "<li>\n",
    "Count the no. of words.\n",
    "</li>\n",
    "<li>\n",
    "And, then find the relevancy of the words\n",
    "</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_counts = count_vector.transform(new)\n",
    "x_new_tfidf = tfid_transformer.transform(x_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 12 15 13  5]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(x_new_tfidf)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This is about Hinduisam'------->soc.religion.christian\n",
      "'Hp Computers are very good'------->sci.electronics\n",
      "'yyy ttt ggg yymee'------->soc.religion.christian\n",
      "' sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content'------->sci.med\n",
      "'Computer graphics is a sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content'------->comp.windows.x\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(new,predicted):\n",
    "    print(\"%r------->%s\"%(doc,train_data.target_names[category]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hence wrapping it up</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "Load the dataset with document and their categories.\n",
    "</li>\n",
    "<li>\n",
    "Now as the Machine learning Algorithm can't handle String values we will transform our data into document term matrix.\n",
    "</li>\n",
    "<li>\n",
    "So, first fit transform data into CountVectorizer to count the no. of words.\n",
    "</li>\n",
    "<li>\n",
    "Then, fit transform data into tfidTransformer to find the relevancy and importance of the words.\n",
    "</li>\n",
    "<li>\n",
    "Hence, By now dataset is being fully converted into numeric terms.\n",
    "</li>\n",
    "<li>\n",
    "So, now Instantiate the model and fit these data into it.\n",
    "</li>\n",
    "<li>\n",
    "load the data to be tested. \n",
    "</li>\n",
    "<li>\n",
    "Apply CountVectoriser and tfidTransformer to it. \n",
    "</li>\n",
    "<li>\n",
    "Then predict the Category of the document to be tested.\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fca9fda0a9fdbcb4750bb1e351e84070f7d170b7023144fd9aeba81a00d984ed"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
